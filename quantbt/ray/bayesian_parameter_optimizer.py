from typing import Type, List, Dict, Any
import asyncio
import ray
import threading
import time
from unittest.mock import AsyncMock
import skopt
import logging
import numpy as np

from quantbt.core.interfaces.strategy import TradingStrategy
from quantbt.core.value_objects.backtest_config import BacktestConfig
from quantbt.ray.optimization.parameter_space import ParameterSpace
from quantbt.ray.optimization.bayesian_optimizer import BayesianOptimizer
from quantbt.ray.optimization.early_stopping import EarlyStopping
from quantbt.ray.backtest_actor import BacktestActor
from quantbt.ray.data_manager import RayDataManager
from quantbt.ray.monitoring.progress_tracker import ProgressTracker
from quantbt.ray.monitoring.simple_monitor import SimpleMonitor

BAR_WIDTH = 40
logger = logging.getLogger(__name__)

class BayesianParameterOptimizer:
    """
    ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë ˆì´ë”© ì „ëµì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìµœì í™”í•˜ëŠ” ë©”ì¸ í´ë˜ìŠ¤.

    ì´ í´ë˜ìŠ¤ëŠ” ìµœì í™” í”„ë¡œì„¸ìŠ¤ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤:
    - ìµœì í™”í•  ì „ëµ (TradingStrategy)
    - íƒìƒ‰í•  íŒŒë¼ë¯¸í„° ê³µê°„ (ParameterSpace)
    - ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • (BacktestConfig)
    - Ray ì•¡í„° ê´€ë¦¬ ë° ë¶„ì‚° ì²˜ë¦¬
    """

    def __init__(
        self,
        strategy_class: Type[TradingStrategy],
        param_space: ParameterSpace,
        config: BacktestConfig,
        num_actors: int = 4,
        n_initial_points: int = 10,
    ):
        """
        BayesianParameterOptimizerë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        Args:
            strategy_class (Type[TradingStrategy]): ìµœì í™”í•  íŠ¸ë ˆì´ë”© ì „ëµ í´ë˜ìŠ¤.
            param_space (ParameterSpace): íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„.
            config (BacktestConfig): ë°±í…ŒìŠ¤íŠ¸ ì„¤ì •.
            num_actors (int): ë³‘ë ¬ ì²˜ë¦¬ì— ì‚¬ìš©í•  Ray ì•¡í„°ì˜ ìˆ˜.
            n_initial_points (int): ë² ì´ì§€ì•ˆ ìµœì í™”ì˜ ì´ˆê¸° ëœë¤ íƒìƒ‰ íšŸìˆ˜.
        """
        self.strategy_class = strategy_class
        self.param_space = param_space
        self.config = config
        self.num_actors = num_actors
        self.n_initial_points = n_initial_points
        self.actors: List[BacktestActor] = []
        self.early_stopper: EarlyStopping = None
        self.stop_display_event = threading.Event()

        self.bayesian_optimizer = BayesianOptimizer(
            space=param_space,
            n_initial_points=n_initial_points,
        )

    def _display_progress(self, progress_tracker: ProgressTracker, monitor: SimpleMonitor, interval: int = 5):
        """ë³„ë„ì˜ ìŠ¤ë ˆë“œì—ì„œ ì§„í–‰ ìƒí™©ì„ ì£¼ê¸°ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤."""
        while not self.stop_display_event.is_set():
            # í™”ë©´ì„ ì§€ìš°ê³  ì»¤ì„œë¥¼ ë§¨ ìœ„ë¡œ ì´ë™
            print("\033[2J\033[H", end="")

            print("=============== Bayesian Optimization Progress ===============")
            print(progress_tracker.format_progress(show_bar=True, bar_width=50))
            print("--------------------------------------------------------------")
            print(monitor.format_summary())
            print("==============================================================")

            time.sleep(interval)

    async def optimize(
        self,
        objective_metric: str = 'sharpe_ratio',
        n_iter: int = 100,
        early_stopping_patience: int = 0,
        early_stopping_min_delta: float = 0.001
    ) -> List[Dict[str, Any]]:
        """
        ë² ì´ì§€ì•ˆ ìµœì í™”ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
        """
        logger.info("ğŸš€ ë² ì´ì§€ì•ˆ ìµœì í™” í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        logger.info(f" - ëª©í‘œ ì§€í‘œ: {objective_metric}")
        logger.info(f" - ì´ ë°˜ë³µ íšŸìˆ˜: {n_iter}")
        logger.info(f" - ë°°ì¹˜ í¬ê¸°: {self.num_actors}")

        if early_stopping_patience > 0:
            patience_in_batches = max(1, early_stopping_patience // self.num_actors)
            self.early_stopper = EarlyStopping(
                patience=patience_in_batches,
                min_delta=early_stopping_min_delta
            )
            logger.info(f" - ì¡°ê¸° ì¢…ë£Œ í™œì„±í™”: patience={patience_in_batches} ë°°ì¹˜ ({early_stopping_patience} ì‹œë„), min_delta={early_stopping_min_delta}")

        progress_tracker = ProgressTracker(total_tasks=n_iter)
        monitor = SimpleMonitor()

        self.stop_display_event.clear()
        display_thread = threading.Thread(
            target=self._display_progress,
            args=(progress_tracker, monitor),
            daemon=True
        )
        display_thread.start()

        if not self.actors:
            if not ray.is_initialized():
                ray.init(
                    num_cpus=self.num_actors,
                    ignore_reinit_error=True,
                    logging_level=logging.INFO,
                    log_to_driver=True
                )
            
            data_manager = RayDataManager.remote()
            shared_data_ref = data_manager.load_real_data.remote(
                symbols=self.config.symbols,
                start_date=self.config.start_date,
                end_date=self.config.end_date,
                timeframe=self.config.timeframe,
            )
            self._initialize_actors(shared_data_ref)

        all_results = []
        progress_tracker.start()
        
        try:
            while progress_tracker.completed_tasks < n_iter:
                batch_size = min(self.num_actors, n_iter - progress_tracker.completed_tasks)
                if batch_size <= 0:
                    break

                params_list = self.bayesian_optimizer.ask(n_points=batch_size)
                logger.info(f"ë°°ì¹˜ ì‹œì‘ | {batch_size}ê°œ íŒŒë¼ë¯¸í„° ìƒì„± (ì´ {progress_tracker.completed_tasks}/{n_iter} ì§„í–‰)")

                tasks = []
                for i, params in enumerate(params_list):
                    actor = self.actors[i]
                    if isinstance(actor, AsyncMock):
                        future = actor.execute_backtest(params, self.strategy_class)
                    else:
                        future = actor.execute_backtest.remote(params, self.strategy_class)
                    tasks.append(future)

                batch_results_raw = await asyncio.gather(*tasks)

                scores, scores_for_check = [], []
                for params, result in zip(params_list, batch_results_raw):
                    score = result.get(objective_metric, 0.0)
                    scores.append(-score)
                    scores_for_check.append(score)

                    monitor_payload = {'params': params, **result}
                    monitor.record_result(monitor_payload)

                    # ì£¼ìš” ì§€í‘œë“¤ì„ ìµœìƒìœ„ ë ˆë²¨ì— ì¶”ê°€í•˜ì—¬ ì ‘ê·¼ì„± í–¥ìƒ
                    trial_result = {
                        'params': params,
                        'result': result,
                        # ì£¼ìš” ì„±ê³¼ ì§€í‘œë“¤ì„ ìµœìƒìœ„ ë ˆë²¨ì— ì¶”ê°€
                        'sharpe_ratio': result.get('sharpe_ratio', 0.0),
                        'calmar_ratio': result.get('calmar_ratio', 0.0),
                        'total_return': result.get('total_return', 0.0),
                        'annual_return': result.get('annual_return', 0.0),
                        'max_drawdown': result.get('max_drawdown', 0.0),
                        'volatility': result.get('volatility', 0.0),
                        'win_rate': result.get('win_rate', 0.0),
                        'profit_factor': result.get('profit_factor', 0.0),
                        'total_trades': result.get('total_trades', 0),
                        'final_equity': result.get('final_equity', 0.0),
                        'success': result.get('success', True)
                    }
                    all_results.append(trial_result)

                progress_tracker.update(completed=len(batch_results_raw))
                
                best_batch_score = max(scores_for_check) if scores_for_check else 0
                avg_batch_score = np.mean(scores_for_check) if scores_for_check else 0
                logger.info(f"ë°°ì¹˜ ì™„ë£Œ | ìµœê³  ì ìˆ˜: {best_batch_score:.4f}, í‰ê·  ì ìˆ˜: {avg_batch_score:.4f}")

                self.bayesian_optimizer.tell(params_list, scores)

                if self.early_stopper:
                    if self.early_stopper.check(best_batch_score):
                        logger.info(f"ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´ ì¶©ì¡±: {self.early_stopper.patience}ë²ˆì˜ ë°°ì¹˜ ë™ì•ˆ ì„±ëŠ¥ ê°œì„  ì—†ìŒ.")
                        break
        finally:
            self.stop_display_event.set()
            display_thread.join(timeout=2)

            logger.info("ğŸ ë² ì´ì§€ì•ˆ ìµœì í™” í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ.")
            print("\033[2J\033[H", end="")
            print("=============== Bayesian Optimization Final Result ===============")
            print(monitor.format_summary())
            print("==================================================================")
        return all_results

    def _initialize_actors(self, shared_data_ref: ray.ObjectRef):
        """
        Ray ë°±í…ŒìŠ¤íŠ¸ ì•¡í„°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        logger.info(f"ì´ˆê¸°í™” ì‹œì‘: {self.num_actors}ê°œì˜ ë°±í…ŒìŠ¤íŠ¸ ì•¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        if not ray.is_initialized():
            ray.init(num_cpus=self.num_actors)
            
        self.actors = [BacktestActor.remote(f"actor_{i}", shared_data_ref) for i in range(self.num_actors)]
        
        config_dict = self.config.to_dict()
        init_tasks = [actor.initialize_engine.remote(config_dict) for actor in self.actors]
        results = ray.get(init_tasks)
        
        if all(results):
            logger.info("âœ… ëª¨ë“  ì•¡í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        else:
            failed_actors = [i for i, r in enumerate(results) if not r]
            logger.error(f"âŒ ë‹¤ìŒ ì•¡í„° ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {failed_actors}")
            raise RuntimeError("ì¼ë¶€ ì•¡í„°ë¥¼ ì´ˆê¸°í™”í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”.") 