#!/usr/bin/env python3
"""
ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë”

ì „ì²´ USDT í˜ì–´ ì‹¬ë³¼ì˜ 1ë¶„ë´‰ ë°ì´í„°ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  DBì— ì €ì¥í•˜ëŠ” ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import argparse
from datetime import datetime, timedelta
from pathlib import Path
import sys
import os

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from quantbt.infrastructure.data import BinanceDataProvider


async def download_all_usdt_data(
    start_date: str,
    end_date: str,
    timeframe: str = "1m",
    batch_size: int = 5,
    export_csv: bool = False,
    csv_dir: str = "./binance_data"
):
    """ì „ì²´ USDT í˜ì–´ ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    
    # ë‚ ì§œ íŒŒì‹±
    try:
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d") + timedelta(days=1) - timedelta(seconds=1)
    except ValueError as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        print("ì˜¬ë°”ë¥¸ í˜•ì‹: YYYY-MM-DD (ì˜ˆ: 2024-01-01)")
        return
    
    print("ğŸš€ ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë” ì‹œì‘")
    print(f"ğŸ“… ë‹¤ìš´ë¡œë“œ ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"â° íƒ€ì„í”„ë ˆì„: {timeframe}")
    print(f"ğŸ”¢ ë°°ì¹˜ í¬ê¸°: {batch_size}")
    print(f"ğŸ“ CSV ë‚´ë³´ë‚´ê¸°: {'ì˜ˆ' if export_csv else 'ì•„ë‹ˆì˜¤'}")
    
    if export_csv:
        print(f"ğŸ“‚ CSV ì €ì¥ ê²½ë¡œ: {csv_dir}")
    
    print("\n" + "="*60)
    
    # ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
    async with BinanceDataProvider() as provider:
        try:
            # ì „ì²´ USDT í˜ì–´ ë‹¤ìš´ë¡œë“œ
            results = await provider.download_all_usdt_symbols(
                start=start,
                end=end,
                timeframe=timeframe,
                batch_size=batch_size
            )
            
            print("\n" + "="*60)
            print("ğŸ“Š ë‹¤ìš´ë¡œë“œ ê²°ê³¼ ìƒì„¸")
            print("="*60)
            
            # ì„±ê³µí•œ ì‹¬ë³¼ë“¤
            successful_symbols = [symbol for symbol, count in results.items() if count > 0]
            failed_symbols = [symbol for symbol, count in results.items() if count == -1]
            empty_symbols = [symbol for symbol, count in results.items() if count == 0]
            
            print(f"âœ… ì„±ê³µ: {len(successful_symbols)}ê°œ ì‹¬ë³¼")
            print(f"âŒ ì‹¤íŒ¨: {len(failed_symbols)}ê°œ ì‹¬ë³¼")
            print(f"âš ï¸ ë°ì´í„° ì—†ìŒ: {len(empty_symbols)}ê°œ ì‹¬ë³¼")
            
            if export_csv and successful_symbols:
                print(f"\nğŸ“„ CSV ë‚´ë³´ë‚´ê¸° ì‹œì‘...")
                
                # ì„±ê³µí•œ ì‹¬ë³¼ë“¤ë§Œ CSVë¡œ ë‚´ë³´ë‚´ê¸°
                exported_files = await provider.export_to_csv(
                    symbols=successful_symbols[:10],  # ì²˜ìŒ 10ê°œë§Œ ë‚´ë³´ë‚´ê¸° (í…ŒìŠ¤íŠ¸ìš©)
                    start=start,
                    end=end,
                    timeframe=timeframe,
                    output_dir=csv_dir
                )
                
                print(f"ğŸ“ {len(exported_files)}ê°œ íŒŒì¼ì´ {csv_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ì €ì¥ì†Œ ì •ë³´ ì¶œë ¥
            storage_info = provider.get_storage_info()
            print(f"\nğŸ’¾ ì €ì¥ì†Œ ì •ë³´:")
            print(f"DB ê²½ë¡œ: {storage_info['db_info'].get('db_path', 'N/A')}")
            print(f"ìºì‹œ ë””ë ‰í† ë¦¬: {storage_info['cache_info'].get('cache_dir', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()


async def download_specific_symbols(
    symbols: list,
    start_date: str,
    end_date: str,
    timeframe: str = "1m",
    export_csv: bool = False,
    csv_dir: str = "./binance_data"
):
    """íŠ¹ì • ì‹¬ë³¼ë“¤ë§Œ ë‹¤ìš´ë¡œë“œ"""
    
    # ë‚ ì§œ íŒŒì‹±
    try:
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d") + timedelta(days=1) - timedelta(seconds=1)
    except ValueError as e:
        print(f"âŒ ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {e}")
        return
    
    print("ğŸ¯ íŠ¹ì • ì‹¬ë³¼ ë‹¤ìš´ë¡œë“œ ì‹œì‘")
    print(f"ğŸ“ˆ ì‹¬ë³¼: {', '.join(symbols)}")
    print(f"ğŸ“… ê¸°ê°„: {start_date} ~ {end_date}")
    print(f"â° íƒ€ì„í”„ë ˆì„: {timeframe}")
    
    async with BinanceDataProvider() as provider:
        try:
            results = {}
            
            for symbol in symbols:
                print(f"\nğŸ“ˆ {symbol} ë‹¤ìš´ë¡œë“œ ì¤‘...")
                
                # ë‹¤ìš´ë¡œë“œ ì „ìš© ë©”ì„œë“œ ì‚¬ìš© (ìºì‹œ ì €ì¥ ì—†ìŒ)
                symbol_counts = await provider._fetch_raw_data_download_only([symbol], start, end, timeframe)
                
                count = symbol_counts.get(symbol, 0)
                if count > 0:
                    results[symbol] = count
                    print(f"âœ… {symbol}: {count}ê°œ ìº”ë“¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
                elif count == 0:
                    results[symbol] = 0
                    print(f"âš ï¸ {symbol}: ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    results[symbol] = -1
                    print(f"âŒ {symbol}: ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")
            
            if export_csv:
                print(f"\nğŸ“„ CSV ë‚´ë³´ë‚´ê¸°...")
                exported_files = await provider.export_to_csv(
                    symbols=symbols,
                    start=start,
                    end=end,
                    timeframe=timeframe,
                    output_dir=csv_dir
                )
                print(f"ğŸ“ {len(exported_files)}ê°œ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ê²°ê³¼ ìš”ì•½
            total_candles = sum(count for count in results.values() if count > 0)
            print(f"\nğŸ“Š ì´ {total_candles:,}ê°œ ìº”ë“¤ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(
        description="ë°”ì´ë‚¸ìŠ¤ ë°ì´í„° ë‹¤ìš´ë¡œë”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì „ì²´ USDT í˜ì–´ ë‹¤ìš´ë¡œë“œ (2024ë…„ 1ì›”)
  python binance_downloader.py --start 2024-01-01 --end 2024-01-31

  # íŠ¹ì • ì‹¬ë³¼ë§Œ ë‹¤ìš´ë¡œë“œ
  python binance_downloader.py --symbols BTCUSDT ETHUSDT --start 2024-01-01 --end 2024-01-07

  # CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
  python binance_downloader.py --symbols BTCUSDT --start 2024-01-01 --end 2024-01-02 --csv --csv-dir ./my_data

  # 5ë¶„ë´‰ ë°ì´í„° ë‹¤ìš´ë¡œë“œ
  python binance_downloader.py --symbols BTCUSDT --start 2024-01-01 --end 2024-01-07 --timeframe 5m
        """
    )
    
    parser.add_argument(
        "--start", 
        required=True,
        help="ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--end", 
        required=True,
        help="ì¢…ë£Œ ë‚ ì§œ (YYYY-MM-DD)"
    )
    
    parser.add_argument(
        "--symbols",
        nargs="+",
        help="ë‹¤ìš´ë¡œë“œí•  ì‹¬ë³¼ë“¤ (ì˜ˆ: BTCUSDT ETHUSDT). ë¯¸ì§€ì •ì‹œ ì „ì²´ USDT í˜ì–´ ë‹¤ìš´ë¡œë“œ"
    )
    
    parser.add_argument(
        "--timeframe",
        default="1m",
        help="íƒ€ì„í”„ë ˆì„ (ê¸°ë³¸ê°’: 1m)"
    )
    
    parser.add_argument(
        "--batch-size",
        type=int,
        default=5,
        help="ë°°ì¹˜ í¬ê¸° (ì „ì²´ ë‹¤ìš´ë¡œë“œì‹œë§Œ ì‚¬ìš©, ê¸°ë³¸ê°’: 5)"
    )
    
    parser.add_argument(
        "--csv",
        action="store_true",
        help="CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°"
    )
    
    parser.add_argument(
        "--csv-dir",
        default="./binance_data",
        help="CSV íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: ./binance_data)"
    )
    
    args = parser.parse_args()
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    if args.symbols:
        # íŠ¹ì • ì‹¬ë³¼ ë‹¤ìš´ë¡œë“œ
        asyncio.run(download_specific_symbols(
            symbols=args.symbols,
            start_date=args.start,
            end_date=args.end,
            timeframe=args.timeframe,
            export_csv=args.csv,
            csv_dir=args.csv_dir
        ))
    else:
        # ì „ì²´ USDT í˜ì–´ ë‹¤ìš´ë¡œë“œ
        asyncio.run(download_all_usdt_data(
            start_date=args.start,
            end_date=args.end,
            timeframe=args.timeframe,
            batch_size=args.batch_size,
            export_csv=args.csv,
            csv_dir=args.csv_dir
        ))


if __name__ == "__main__":
    main() 